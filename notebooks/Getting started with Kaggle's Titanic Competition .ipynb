{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting started: Kaggle's Titanic Competition\n",
    "\n",
    "Kaggle is already established as the best place which hosts machine learning competitions. If you do not know it already, then it's time to do it.\n",
    "\n",
    "__[Titanic Competition](https://www.kaggle.com/c/titanic)__ is perhaps the first competition which one should try. Of course, if you are already an experienced data scientist, than you can skip to an advanced competition.\n",
    "\n",
    "The purpose of the competition is to learn if a passenger has survived or not. We illustrate some steps and ideas one can apply to compete in this learning competition using the available tools one can find in rapaio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%jars /home/ati/work/out/artifacts/rapaio_jar/rapaio.jar /home/ati/work/out/artifacts/rapaio_jar/fastutil-8.2.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import java.util.stream.*;\n",
    "\n",
    "import rapaio.datasets.*;\n",
    "import rapaio.data.*;\n",
    "import rapaio.sys.*;\n",
    "import rapaio.graphics.*;\n",
    "import rapaio.graphics.plot.*;\n",
    "import static rapaio.graphics.Plotter.*;\n",
    "import rapaio.io.*;\n",
    "import rapaio.core.distributions.*;\n",
    "import rapaio.core.*;\n",
    "import rapaio.core.tests.*;\n",
    "import rapaio.core.tools.*;\n",
    "import rapaio.core.stat.*;\n",
    "import rapaio.ml.classifier.*;\n",
    "import rapaio.ml.classifier.tree.*;\n",
    "import rapaio.experiment.ml.eval.*;\n",
    "import rapaio.ml.classifier.tree.*;\n",
    "import rapaio.ml.classifier.ensemble.*;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rapaio.printer.StandardPrinter@6bf79586"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WS.getPrinter().withGraphicWidth(800);\n",
    "WS.getPrinter().withGraphicHeight(600);\n",
    "WS.getPrinter().withTextWidth(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Get the data\n",
    "\n",
    "The purpose of the competition is to predict which passengers have survived or not. The available data has two parts. The first part consists in a data set which contains what happened with some passengers and some related information like sex, cabin, age, class, etc. This data set contains information regarding their survival. The purpose why this data set contains survival data is because it will be used to train a model which learns how to decide if a passenger survives or not. This is the `train.csv`. The other file is a data set which contains data about another set of passenger, this time without knowing if they survived or not. They contain, however an identification number. This data set is `test.csv` and this is used to make predictions. Those predictions should be similar with the provided `gendermodel.csv`.\n",
    "\n",
    "We also have to take a look of the data description provided on __[contest dedicated page](https://www.kaggle.com/c/titanic/data)__:\n",
    "\n",
    "```\n",
    "VARIABLE DESCRIPTIONS:\n",
    "survival Survival\n",
    "(0 = No; 1 = Yes)\n",
    "pclass Passenger Class\n",
    "(1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name Name\n",
    "sex Sex\n",
    "age Age\n",
    "sibsp Number of Siblings/Spouses Aboard\n",
    "parch Number of Parents/Children Aboard\n",
    "ticket Ticket Number\n",
    "fare Passenger Fare\n",
    "cabin Cabin\n",
    "embarked Port of Embarkation\n",
    "(C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    "1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    "If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored. The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling: Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse: Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent: Mother or Father of Passenger Aboard Titanic\n",
    "Child: Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws. Some children travelled\n",
    "only with a nanny, therefore parch=0 for them. As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations.\n",
    "```\n",
    "\n",
    "The first step in our adventure is to download those 3 data file in *csv* format. You can do it from __[data section](https://www.kaggle.com/c/titanic/data)__ of the competition. Let's suppose you downloaded somewhere in a local folder. We will name this folder `data` folder, and actually it can have any name you would like.\n",
    "\n",
    "### 1.2 Read train data from csv file\n",
    "\n",
    "Because the data is small we can load the whole data in memory with no problems.\n",
    "\n",
    "Let's see how we can load the data into memory. In rapaio the sets of data are loaded into the form of *frames* (`rapaio.data.Frame`). A frame is basically a tabular data, with columns for each variable (feature) and rows for each instance (in our case for each passenger).\n",
    "\n",
    "\n",
    "A first try of loading the train data set and see what has happened is the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Summary\n",
      "=============\n",
      "* rowCount: 891\n",
      "* complete: 889/891\n",
      "* varCount: 12\n",
      "* varNames: \n",
      "\n",
      " 0. PassengerId : double  | 4.   Sex : nominal |  8.   Ticket : nominal |\n",
      " 1.    Survived : binary  | 5.   Age : nominal |  9.     Fare : double  |\n",
      " 2.      Pclass : double  | 6. SibSp : double  | 10.    Cabin : nominal |\n",
      " 3.        Name : nominal | 7. Parch : double  | 11. Embarked : nominal |\n",
      "\n",
      "      PassengerId         Survived           Pclass \n",
      "   Min. :   1.000     Min. : 0.000     Min. : 1.000 \n",
      "1st Qu. : 223.500  1st Qu. : 0.000  1st Qu. : 2.000 \n",
      " Median : 446.000   Median : 0.000   Median : 3.000 \n",
      "   Mean : 446.000     Mean : 0.384     Mean : 2.309 \n",
      "2nd Qu. : 668.500  2nd Qu. : 1.000  2nd Qu. : 3.000 \n",
      "   Max. : 891.000     Max. : 1.000     Max. : 3.000 \n",
      "                                                    \n",
      "                                                       Name           Sex            Age            SibSp \n",
      "                            \"Braund, Mr. Owen Harris\" :   1    male : 577          : 177     Min. : 0.000 \n",
      "\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" :   1  female : 314       24 :  30  1st Qu. : 0.000 \n",
      "                             \"Heikkinen, Miss. Laina\" :   1                     22 :  27   Median : 0.000 \n",
      "       \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" :   1                     18 :  26     Mean : 0.523 \n",
      "                           \"Allen, Mr. William Henry\" :   1                     28 :  25  2nd Qu. : 1.000 \n",
      "                                   \"Moran, Mr. James\" :   1                     19 :  25     Max. : 8.000 \n",
      "                                              (Other) : 885                (Other) : 581                  \n",
      "          Parch          Ticket               Fare              Cabin    Embarked \n",
      "   Min. : 0.000    347082 :   7     Min. :   0.000              : 687     S : 644 \n",
      "1st Qu. : 0.000      1601 :   7  1st Qu. :   7.910           G6 :   4     C : 168 \n",
      " Median : 0.000  CA. 2343 :   7   Median :  14.454  C23 C25 C27 :   4     Q :  77 \n",
      "   Mean : 0.382   3101295 :   6     Mean :  32.204      B96 B98 :   4  NA's :   2 \n",
      "2nd Qu. : 0.000   CA 2144 :   6  2nd Qu. :  31.000          F33 :   3             \n",
      "   Max. : 6.000    347088 :   6     Max. : 512.329         E101 :   3             \n",
      "                  (Other) : 852                         (Other) : 186             \n"
     ]
    }
   ],
   "source": [
    "String root = \"/home/ati/work/rapaio-kaggle/src/titanic/\";\n",
    "new Csv().read(root + \"train.csv\").printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we interpret the output of the frame's summary?\n",
    "\n",
    "* We loaded a frame which has $891$ rows and $12$ columns (variables)\n",
    "* From all the rows, $889$ are complete (non missing data)\n",
    "* The name of the variables are listed, together with their types\n",
    "* It follows a data summary for the frame: 6 number summary for numeric variables, most frequent levels for nominal variables\n",
    "\n",
    "Let's inspect each variable and see how it fits our needs.\n",
    "\n",
    "**PassengedId**\n",
    "\n",
    "The type for this variable is index (integer values). This field looks like an identifier for the passenger, so from our point of view the sorting is not required. What we can do, but is not required, is to change the field type to nominal. Anyway, we do not need this field for learning since it should be unique for each instance, thus the predictive power is null. We will ignore it for now since we will not consider it for learning\n",
    "\n",
    "**Survived**\n",
    "\n",
    "This is our target variable. It is parsed as binary, but since we do classification, we will change it's type to nominal. We do that directly from the csv parsing, by indicating that we want Survived parsed as nominal variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Summary\n",
      "=============\n",
      "* rowCount: 891\n",
      "* complete: 889/891\n",
      "* varCount: 12\n",
      "* varNames: \n",
      "\n",
      " 0. PassengerId : double  | 4.   Sex : nominal |  8.   Ticket : nominal |\n",
      " 1.    Survived : nominal | 5.   Age : nominal |  9.     Fare : double  |\n",
      " 2.      Pclass : double  | 6. SibSp : double  | 10.    Cabin : nominal |\n",
      " 3.        Name : nominal | 7. Parch : double  | 11. Embarked : nominal |\n",
      "\n",
      "      PassengerId  Survived           Pclass                                                         Name \n",
      "   Min. :   1.000   0 : 549     Min. : 1.000                              \"Braund, Mr. Owen Harris\" :   1 \n",
      "1st Qu. : 223.500   1 : 342  1st Qu. : 2.000  \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" :   1 \n",
      " Median : 446.000             Median : 3.000                               \"Heikkinen, Miss. Laina\" :   1 \n",
      "   Mean : 446.000               Mean : 2.309         \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" :   1 \n",
      "2nd Qu. : 668.500            2nd Qu. : 3.000                             \"Allen, Mr. William Henry\" :   1 \n",
      "   Max. : 891.000               Max. : 3.000                                     \"Moran, Mr. James\" :   1 \n",
      "                                                                                            (Other) : 885 \n",
      "         Sex            Age            SibSp            Parch          Ticket               Fare \n",
      "  male : 577          : 177     Min. : 0.000     Min. : 0.000    347082 :   7     Min. :   0.000 \n",
      "female : 314       24 :  30  1st Qu. : 0.000  1st Qu. : 0.000      1601 :   7  1st Qu. :   7.910 \n",
      "                   22 :  27   Median : 0.000   Median : 0.000  CA. 2343 :   7   Median :  14.454 \n",
      "                   18 :  26     Mean : 0.523     Mean : 0.382   3101295 :   6     Mean :  32.204 \n",
      "                   28 :  25  2nd Qu. : 1.000  2nd Qu. : 0.000   CA 2144 :   6  2nd Qu. :  31.000 \n",
      "                   19 :  25     Max. : 8.000     Max. : 6.000    347088 :   6     Max. : 512.329 \n",
      "              (Other) : 581                                     (Other) : 852                    \n",
      "            Cabin    Embarked \n",
      "            : 687     S : 644 \n",
      "         G6 :   4     C : 168 \n",
      "C23 C25 C27 :   4     Q :  77 \n",
      "    B96 B98 :   4  NA's :   2 \n",
      "        F33 :   3             \n",
      "       E101 :   3             \n",
      "    (Other) : 186             \n"
     ]
    }
   ],
   "source": [
    "new Csv()\n",
    ".withTypes(VType.NOMINAL, \"Survived\")\n",
    ".read(root + \"train.csv\")\n",
    ".printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And notice how type of the `Survived` variable changed to nominal.\n",
    "\n",
    "\n",
    "**Pclass**\n",
    "\n",
    "This variable has index type. We can keep it like it is or we can change it to nominal. Both ways can be useful. For example parsed as index could give an interpretation to the order. We can say that somehow, because of ordering class 1 is lower than class 2, and class 2 is between classes 1 and 3. At the same time we can keep it as nominal if we do not want to use the ordering. Let's choose nominal for now, considering that 1,2 and 3 are just labels for type of tickets, with no other meaning attached. We proceed in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Summary\n",
      "=============\n",
      "* rowCount: 891\n",
      "* complete: 889/891\n",
      "* varCount: 12\n",
      "* varNames: \n",
      "\n",
      " 0. PassengerId : double  | 4.   Sex : nominal |  8.   Ticket : nominal |\n",
      " 1.    Survived : nominal | 5.   Age : nominal |  9.     Fare : double  |\n",
      " 2.      Pclass : nominal | 6. SibSp : double  | 10.    Cabin : nominal |\n",
      " 3.        Name : nominal | 7. Parch : double  | 11. Embarked : nominal |\n",
      "\n",
      "      PassengerId  Survived   Pclass                                                         Name \n",
      "   Min. :   1.000   0 : 549  3 : 491                              \"Braund, Mr. Owen Harris\" :   1 \n",
      "1st Qu. : 223.500   1 : 342  1 : 216  \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" :   1 \n",
      " Median : 446.000            2 : 184                               \"Heikkinen, Miss. Laina\" :   1 \n",
      "   Mean : 446.000                            \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" :   1 \n",
      "2nd Qu. : 668.500                                                \"Allen, Mr. William Henry\" :   1 \n",
      "   Max. : 891.000                                                        \"Moran, Mr. James\" :   1 \n",
      "                                                                                    (Other) : 885 \n",
      "         Sex            Age            SibSp            Parch          Ticket               Fare \n",
      "  male : 577          : 177     Min. : 0.000     Min. : 0.000    347082 :   7     Min. :   0.000 \n",
      "female : 314       24 :  30  1st Qu. : 0.000  1st Qu. : 0.000      1601 :   7  1st Qu. :   7.910 \n",
      "                   22 :  27   Median : 0.000   Median : 0.000  CA. 2343 :   7   Median :  14.454 \n",
      "                   18 :  26     Mean : 0.523     Mean : 0.382   3101295 :   6     Mean :  32.204 \n",
      "                   28 :  25  2nd Qu. : 1.000  2nd Qu. : 0.000   CA 2144 :   6  2nd Qu. :  31.000 \n",
      "                   19 :  25     Max. : 8.000     Max. : 6.000    347088 :   6     Max. : 512.329 \n",
      "              (Other) : 581                                     (Other) : 852                    \n",
      "            Cabin    Embarked \n",
      "            : 687     S : 644 \n",
      "         G6 :   4     C : 168 \n",
      "C23 C25 C27 :   4     Q :  77 \n",
      "    B96 B98 :   4  NA's :   2 \n",
      "        F33 :   3             \n",
      "       E101 :   3             \n",
      "    (Other) : 186             \n"
     ]
    }
   ],
   "source": [
    "new Csv()\n",
    ".withTypes(VType.NOMINAL, \"Survived\", \"Pclass\")\n",
    ".read(root + \"train.csv\")\n",
    ".printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we append the variable name after `Survived`. This is possible since the `withTypes` method specify a type, and follows a dynamic array of strings, for the names of variables.\n",
    "\n",
    "**Name**\n",
    "\n",
    "This is the passenger names and the values are unique. As it is, the predictive power of this field is null. We keep it as it is. Note that it contains valuable information, but not in this direct form.\n",
    "\n",
    "**Sex**\n",
    "\n",
    "This field specifies the gender of the passenger. We have $577$ males and $314$ females.\n",
    "\n",
    "**Age**\n",
    "\n",
    "This field specifies the age of an passenger. We would expect that to parse this variable as numeric or at leas index, but is nominal. Why that happened? Notice that the values looks like numbers. But the first value (the most frequent one, $117$ instances) has nothing specified. Well, the variable is nominal has to do with how *Csv* parsing handles missing values. By default, the *csv* parsing considers as missing values only the string \"?\". But the most frequent value in this field is empty string \"\". This means that empty string is not considered a missing value. Because empty string can't produce numbers from parsing, the variable is *promoted* to nominal.\n",
    "\n",
    "We can customize the missing value handling by specifying the valid strings for that purpose. We use `.useNAValues(String...naValues)` to tell the parser all the valid strings which are missing values. In our case we want just the empty string to be a missing value. When the parser will found an empty string it will set the variable value as missing value. It will *not promote* variable to nominal, since a missing value is a legal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Summary\n",
      "=============\n",
      "* rowCount: 891\n",
      "* complete: 183/891\n",
      "* varCount: 12\n",
      "* varNames: \n",
      "\n",
      " 0. PassengerId : double  | 4.   Sex : nominal |  8.   Ticket : nominal |\n",
      " 1.    Survived : nominal | 5.   Age : double  |  9.     Fare : double  |\n",
      " 2.      Pclass : nominal | 6. SibSp : double  | 10.    Cabin : nominal |\n",
      " 3.        Name : nominal | 7. Parch : double  | 11. Embarked : nominal |\n",
      "\n",
      "      PassengerId  Survived   Pclass                                                         Name \n",
      "   Min. :   1.000   0 : 549  3 : 491                              \"Braund, Mr. Owen Harris\" :   1 \n",
      "1st Qu. : 223.500   1 : 342  1 : 216  \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" :   1 \n",
      " Median : 446.000            2 : 184                               \"Heikkinen, Miss. Laina\" :   1 \n",
      "   Mean : 446.000                            \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" :   1 \n",
      "2nd Qu. : 668.500                                                \"Allen, Mr. William Henry\" :   1 \n",
      "   Max. : 891.000                                                        \"Moran, Mr. James\" :   1 \n",
      "                                                                                    (Other) : 885 \n",
      "         Sex               Age            SibSp            Parch          Ticket               Fare \n",
      "  male : 577     Min. :  0.420     Min. : 0.000     Min. : 0.000    347082 :   7     Min. :   0.000 \n",
      "female : 314  1st Qu. : 20.125  1st Qu. : 0.000  1st Qu. : 0.000      1601 :   7  1st Qu. :   7.910 \n",
      "               Median : 28.000   Median : 0.000   Median : 0.000  CA. 2343 :   7   Median :  14.454 \n",
      "                 Mean : 29.699     Mean : 0.523     Mean : 0.382   3101295 :   6     Mean :  32.204 \n",
      "              2nd Qu. : 38.000  2nd Qu. : 1.000  2nd Qu. : 0.000   CA 2144 :   6  2nd Qu. :  31.000 \n",
      "                 Max. : 80.000     Max. : 8.000     Max. : 6.000    347088 :   6     Max. : 512.329 \n",
      "                 NA's :    177                                     (Other) : 852                    \n",
      "            Cabin    Embarked \n",
      "         G6 :   4     S : 644 \n",
      "C23 C25 C27 :   4     C : 168 \n",
      "    B96 B98 :   4     Q :  77 \n",
      "        F33 :   3  NA's :   2 \n",
      "       E101 :   3             \n",
      "    (Other) : 183             \n",
      "       NA's : 687             \n"
     ]
    }
   ],
   "source": [
    "new Csv()\n",
    ".withNAValues(\"\")\n",
    ".withTypes(VType.NOMINAL, \"Survived\", \"Pclass\")\n",
    ".read(root + \"train.csv\")\n",
    ".printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what happened: *Age* field is now numeric and it contains $177$ missing values.\n",
    "\n",
    "**SibSp**\n",
    "\n",
    "It's meaning is \"siblings/spouses\". It's parsed as index, which is natural. In pathological cases with sick imagination we can consider a \"quarter of a wife\" for example.\n",
    "\n",
    "**Parch**\n",
    "\n",
    "It's meaning is \"parents/children\". It is naturally parsed as index.\n",
    "\n",
    "**Ticket**\n",
    "\n",
    "This is the code of the ticket. Probably a family can have the same ticket, thus must be the reason why the frequencies have values up to $$7$$. This field is nominal. It has low predictive power used directly. Perhaps contains valuable information, but used directly in row format would not help much.\n",
    "\n",
    "**Fare**\n",
    "\n",
    "This is the price for passenger fare and should be numeric, like it is.\n",
    "\n",
    "**Cabin**\n",
    "\n",
    "Code of the passenger's cabin, parsed as nominal. Same notes as for `Ticket` variable.\n",
    "\n",
    "**Embarked**\n",
    "\n",
    "Code for the embarking city, which could be: C = Cherbourg, Q = Queenstown, S = Southampton. It's parsed as nominal and has $2$ missing values.\n",
    "\n",
    "If we are content with our parsing, we load data into a data frame for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Summary\n",
      "=============\n",
      "* rowCount: 891\n",
      "* complete: 183/891\n",
      "* varCount: 12\n",
      "* varNames: \n",
      "\n",
      " 0. PassengerId : double  | 4.   Sex : nominal |  8.   Ticket : nominal |\n",
      " 1.    Survived : nominal | 5.   Age : double  |  9.     Fare : double  |\n",
      " 2.      Pclass : nominal | 6. SibSp : double  | 10.    Cabin : nominal |\n",
      " 3.        Name : nominal | 7. Parch : double  | 11. Embarked : nominal |\n",
      "\n",
      "      PassengerId  Survived   Pclass                                                         Name \n",
      "   Min. :   1.000   0 : 549  3 : 491                              \"Braund, Mr. Owen Harris\" :   1 \n",
      "1st Qu. : 223.500   1 : 342  1 : 216  \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\" :   1 \n",
      " Median : 446.000            2 : 184                               \"Heikkinen, Miss. Laina\" :   1 \n",
      "   Mean : 446.000                            \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\" :   1 \n",
      "2nd Qu. : 668.500                                                \"Allen, Mr. William Henry\" :   1 \n",
      "   Max. : 891.000                                                        \"Moran, Mr. James\" :   1 \n",
      "                                                                                    (Other) : 885 \n",
      "         Sex               Age            SibSp            Parch          Ticket               Fare \n",
      "  male : 577     Min. :  0.420     Min. : 0.000     Min. : 0.000    347082 :   7     Min. :   0.000 \n",
      "female : 314  1st Qu. : 20.125  1st Qu. : 0.000  1st Qu. : 0.000      1601 :   7  1st Qu. :   7.910 \n",
      "               Median : 28.000   Median : 0.000   Median : 0.000  CA. 2343 :   7   Median :  14.454 \n",
      "                 Mean : 29.699     Mean : 0.523     Mean : 0.382   3101295 :   6     Mean :  32.204 \n",
      "              2nd Qu. : 38.000  2nd Qu. : 1.000  2nd Qu. : 0.000   CA 2144 :   6  2nd Qu. :  31.000 \n",
      "                 Max. : 80.000     Max. : 8.000     Max. : 6.000    347088 :   6     Max. : 512.329 \n",
      "                 NA's :    177                                     (Other) : 852                    \n",
      "            Cabin    Embarked \n",
      "         G6 :   4     S : 644 \n",
      "C23 C25 C27 :   4     C : 168 \n",
      "    B96 B98 :   4     Q :  77 \n",
      "        F33 :   3  NA's :   2 \n",
      "       E101 :   3             \n",
      "    (Other) : 183             \n",
      "       NA's : 687             \n"
     ]
    }
   ],
   "source": [
    "Frame train = new Csv().withNAValues(\"\").withTypes(VType.NOMINAL, \"Survived\", \"Pclass\")\n",
    ".read(root + \"train.csv\");\n",
    "train.printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read test data from *csv* file\n",
    "\n",
    "Once we have a training frame we can load also the test data. We do that to take a look at the frame and because data is small and there is no memory or time problem cost associated with it. To avoid adding again the *csv* options and to get identical levels nominal variables, we use a different way to parse the data set. We specify variable types by frame templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Frame test = new Csv().withNAValues(\"\").withTemplate(train).read(root + \"test.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead to specify again the preferred types for variables, we use train frame as a template for variable types. This has also the side effect that the encoding of categorical variables is identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Summary\n",
      "=============\n",
      "* rowCount: 418\n",
      "* complete: 87/418\n",
      "* varCount: 11\n",
      "* varNames: \n",
      "\n",
      " 0. PassengerId : double  | 4.    Age : double  |  8.     Fare : double  |\n",
      " 1.      Pclass : nominal | 5.  SibSp : double  |  9.    Cabin : nominal |\n",
      " 2.        Name : nominal | 6.  Parch : double  | 10. Embarked : nominal |\n",
      " 3.         Sex : nominal | 7. Ticket : nominal |                         \n",
      "\n",
      "       PassengerId   Pclass                                                  Name           Sex \n",
      "   Min. :  892.000  3 : 218                          \"Connolly, Miss. Kate\" :   1    male : 266 \n",
      "1st Qu. :  996.250  1 : 107                              \"Kelly, Mr. James\" :   1  female : 152 \n",
      " Median : 1100.500  2 :  93              \"Wilkes, Mrs. James (Ellen Needs)\" :   1               \n",
      "   Mean : 1100.500                              \"Myles, Mr. Thomas Francis\" :   1               \n",
      "2nd Qu. : 1204.750                                       \"Wirz, Mr. Albert\" :   1               \n",
      "   Max. : 1309.000           \"Hirvonen, Mrs. Alexander (Helga E Lindqvist)\" :   1               \n",
      "                                                                    (Other) : 412               \n",
      "             Age            SibSp            Parch          Ticket               Fare                  Cabin \n",
      "   Min. :  0.170     Min. : 0.000     Min. : 0.000  PC 17608 :   5     Min. :   0.000  B57 B59 B63 B66 :   3 \n",
      "1st Qu. : 21.000  1st Qu. : 0.000  1st Qu. : 0.000  CA. 2343 :   4  1st Qu. :   7.896      C23 C25 C27 :   2 \n",
      " Median : 27.000   Median : 0.000   Median : 0.000    113503 :   4   Median :  14.454               F4 :   2 \n",
      "   Mean : 30.273     Mean : 0.447     Mean : 0.392    347077 :   3     Mean :  35.627              C78 :   2 \n",
      "2nd Qu. : 39.000  2nd Qu. : 1.000  2nd Qu. : 0.000     16966 :   3  2nd Qu. :  31.500              E34 :   2 \n",
      "   Max. : 76.000     Max. : 8.000     Max. : 9.000  PC 17483 :   3     Max. : 512.329          (Other) :  78 \n",
      "   NA's :     86                                     (Other) : 396     NA's :       1             NA's : 327 \n",
      "Embarked \n",
      " S : 270 \n",
      " C : 102 \n",
      " Q :  46 \n",
      "         \n",
      "         \n",
      "         \n",
      "         \n"
     ]
    }
   ],
   "source": [
    "test.printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that we don't have *Survived* variable anymore. This is correct since this is what we have to predict. Note also that the types for the remaining variables are the same with training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build simple models\n",
    "\n",
    "### 2.1 Build a majority model\n",
    "\n",
    "To make a first submission we will build a very simple model, which classifies with a single value all instances. This value is the majority label.\n",
    "\n",
    "Let's inspect at how target variable look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "    -   -\n",
      "  549 342\n"
     ]
    }
   ],
   "source": [
    "DVector.fromCount(false, train.rvar(\"Survived\")).printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already new from the summary, the number of passengers who didn't survived is lower than those who did. Let's see percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "          -         -\n",
      "  0.6161616 0.3838384\n"
     ]
    }
   ],
   "source": [
    "DVector.fromCount(false, train.rvar(\"Survived\")).normalize().printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that there are about $61\\%$ of passengers who did not survived. We will create a submit data set, which we will save for later submission. How we can do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VarNominal prediction = VarNominal.from(test.rowCount(), row -> \"0\").withName(\"Survived\");\n",
    "Frame submit = SolidFrame.byVars(test.rvar(\"PassengerId\"), prediction);\n",
    "\n",
    "new Csv().withQuotes(false).write(submit, root + \"majority_submit.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first line we created a new nominal variable. The size of the new variable is the number of rows from the test frame. For each row we produce the same label `\"0\"`. We name this variable `Survived`.\n",
    "\n",
    "In the second line we created a new frame taking the variable named `PassengerId` from the test data set and the new prediction variable.\n",
    "\n",
    "In the last line we wrote a new csv file with the csv parsing utility, taking care to not write quotes. We can submit this file and see which are the results.\n",
    "\n",
    "![Submission result with majority classifier](images/titanic-majority-submit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build a simple gender model\n",
    "\n",
    "It has been said that \"women and children first\" really happened during Titanic tragedy. If this was true or not, we do not know. But we can use data to see if we are hearing the same story. For now we will take the gender and see if it had an influence. We will build a contingency table for variables `Sex` and `Survived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0   1 total\n",
      "   male 468 109   577\n",
      " female  81 233   314\n",
      "  total 549 342   891\n"
     ]
    }
   ],
   "source": [
    "DTable.fromCounts(train.rvar(\"Sex\"), train.rvar(\"Survived\"), false).printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rows we have levels of `Sex` variable. On columns we have levels of `Sex` variable. Cells are computed as counts. What we see is that there are a lot of men who did not survived and a lot of women who does. We will normalize on rows to take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0         1 total\n",
      "   male 0.8110919 0.1889081     1\n",
      " female 0.2579618 0.7420382     1\n",
      "  total 1.0690536 0.9309464     2\n"
     ]
    }
   ],
   "source": [
    "DTable.fromCounts(train.rvar(\"Sex\"), train.rvar(\"Survived\"), false).normalizeOnRows().printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that men survived with a rate of $0.19$ and women with $0.74$. The values are so obvious, we need no hypothesis testing to check that this variable is significant for classification. We will build a simple model where we predict as survived all the women and not survived all the men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Var prediction = VarNominal.from(test.rowCount(), row -> test.getLabel(row, \"Sex\").equals(\"male\") \n",
    "? \"0\" : \"1\").withName(\"Survived\");\n",
    "Frame submit = SolidFrame.byVars(test.rvar(\"PassengerId\"), prediction);\n",
    "new Csv().withQuotes(false).write(submit, root + \"gender_submit.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__![Submission result with gender classifier](images/titanic-gender-submit.png)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tree model\n",
    "\n",
    "Building models in the manual way is often not the way to go. This process is tedious and time consuming. There are already built automated procedures, which incorporate miscellaneous approaches to learn a classifier. One of the often used models is the decision tree. Decision trees are greedy local approximations build in a recursive greedy fashion. Often the split decision at node level uses a single feature. At leave nodes a simple majority classifier creates the classification rule.\n",
    "\n",
    "### 3.1 Gender model with decision tree\n",
    "Initially we will build a CART decision tree using as input feature the *Sex* variable. We do this to exemplify how a manual rule can be created in an automated fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTree model\n",
      "================\n",
      "\n",
      "Description:\n",
      "CTree {varSelector=VarSelector[ALL];\n",
      "minCount=1;\n",
      "maxDepth=-1;\n",
      "tests=BINARY:BinaryBinary,DOUBLE:NumericBinary,NOMINAL:NominalBinary,INT:NumericBinary;\n",
      "func=GiniGain;\n",
      "split=ToAllWeighted;\n",
      "}\n",
      "\n",
      "Capabilities:\n",
      "types inputs/targets: BINARY,INT,NOMINAL,DOUBLE/NOMINAL\n",
      "counts inputs/targets: [1,1000000] / [1,1]\n",
      "missing inputs/targets: true/false\n",
      "\n",
      "Learned model:\n",
      "input vars: \n",
      " 0. Sex : NOMINAL  |               \n",
      "\n",
      "target vars:\n",
      "> Survived : NOMINAL [?,0,1]\n",
      "\n",
      "\n",
      "total number of nodes: 3\n",
      "total number of leaves: 2\n",
      "description:\n",
      "split, n/err, classes (densities) [* if is leaf / purity if not]\n",
      "\n",
      "|- 0. root    891/342 0 (0.616 0.384 ) [0.139648]\n",
      "|   |- 1. Sex = 'female'    314/81 1 (0.258 0.742 ) *\n",
      "|   |- 2. Sex != 'female'    577/109 0 (0.811 0.189 ) *\n"
     ]
    }
   ],
   "source": [
    "Frame tr = train.mapVars(\"Survived,Sex\");\n",
    "CTree tree = CTree.newCART();\n",
    "tree.fit(tr, \"Survived\");\n",
    "tree.printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a closer look at the last three rows from the output, one can identify our manual rule. Basically the interpretation is: *\"all the females survived, all the males did not\"*. For exemplification purposes we build also the submit file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// fit the tree to test data frame\n",
    "CPrediction pred = tree.predict(test);\n",
    "// build teh submission\n",
    "Frame submit = SolidFrame.byVars(test.rvar(\"PassengerId\"),pred.firstClasses().withName(\"Survived\"));\n",
    "// write to a submit file\n",
    "new Csv().withQuotes(false).write(submit, root + \"tree1-model.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Enrich tree by using other features\n",
    "\n",
    "Our training data set has more than a single input feature. Thus We can state we didn't use all the information available. We will add now the class and embarking port and see how it behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTree model\n",
      "================\n",
      "\n",
      "Description:\n",
      "CTree {varSelector=VarSelector[ALL];\n",
      "minCount=1;\n",
      "maxDepth=-1;\n",
      "tests=BINARY:BinaryBinary,DOUBLE:NumericBinary,NOMINAL:NominalBinary,INT:NumericBinary;\n",
      "func=GiniGain;\n",
      "split=ToAllWeighted;\n",
      "}\n",
      "\n",
      "Capabilities:\n",
      "types inputs/targets: BINARY,INT,NOMINAL,DOUBLE/NOMINAL\n",
      "counts inputs/targets: [1,1000000] / [1,1]\n",
      "missing inputs/targets: true/false\n",
      "\n",
      "Learned model:\n",
      "input vars: \n",
      " 0. Sex : NOMINAL  | 1. Pclass : NOMINAL  | 2. Embarked : NOMINAL  |\n",
      "\n",
      "target vars:\n",
      "> Survived : NOMINAL [?,0,1]\n",
      "\n",
      "\n",
      "total number of nodes: 17\n",
      "total number of leaves: 9\n",
      "description:\n",
      "split, n/err, classes (densities) [* if is leaf / purity if not]\n",
      "\n",
      "|- 0. root    891/342 0 (0.616 0.384 ) [0.139648]\n",
      "|   |- 1. Sex = 'female'    314/81 1 (0.258 0.742 ) [0.0204665]\n",
      "|   |   |- 3. Pclass = '2'    76/6 1 (0.079 0.921 ) [0.0003369]\n",
      "|   |   |   |- 7. Embarked = 'Q'    2/0 1 (0 1 ) *\n",
      "|   |   |   |- 8. Embarked != 'Q'    74/6 1 (0.081 0.919 ) [0.0013737]\n",
      "|   |   |   |   |- 13. Embarked = 'C'    7/0 1 (0 1 ) *\n",
      "|   |   |   |   |- 14. Embarked != 'C'    67/6 1 (0.09 0.91 ) *\n",
      "|   |   |- 4. Pclass != '2'    238/75 1 (0.315 0.685 ) [0.0009409]\n",
      "|   |   |   |- 9. Embarked = 'Q'    36/9 1 (0.262 0.738 ) *\n",
      "|   |   |   |- 10. Embarked != 'Q'    204/66 1 (0.324 0.676 ) [0.0348789]\n",
      "|   |   |   |   |- 15. Embarked = 'C'    68/9 1 (0.135 0.865 ) *\n",
      "|   |   |   |   |- 16. Embarked != 'C'    138/57 1 (0.416 0.584 ) *\n",
      "|   |- 2. Sex != 'female'    577/109 0 (0.811 0.189 ) [0.0020493]\n",
      "|   |   |- 5. Embarked = 'Q'    41/3 0 (0.927 0.073 ) *\n",
      "|   |   |- 6. Embarked != 'Q'    536/106 0 (0.802 0.198 ) [0.0049791]\n",
      "|   |   |   |- 11. Embarked = 'C'    95/29 0 (0.695 0.305 ) *\n",
      "|   |   |   |- 12. Embarked != 'C'    441/77 0 (0.825 0.175 ) *\n"
     ]
    }
   ],
   "source": [
    "Frame tr = train.mapVars(\"Survived,Sex,Pclass,Embarked\");\n",
    "\n",
    "CTree tree = CTree.newCART();\n",
    "tree.fit(tr, \"Survived\");\n",
    "tree.printSummary();\n",
    "\n",
    "CPrediction pred = tree.predict(test);\n",
    "Frame submit = SolidFrame.byVars(test.rvar(\"PassengerId\"),pred.firstClasses().withName(\"Survived\"));\n",
    "new Csv().withQuotes(false).write(submit, root + \"tree2-model.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is much richer and there are more chances to be better. This is what happened after submission.\n",
    "\n",
    "__![Results after submission of enriched tree](images/titanic-tree2-submit.png)__\n",
    "\n",
    "**Nice!**. We advanced $704$ positions and improved our score with $0.01435$. On public leader board we have a nice $0.77990$ accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Overfitting with trees\n",
    "\n",
    "What about using other input features to improve our prediction accuracy? There are some of them which we can include directly, with no changes: *Age*,*Fare*,*SibSp* and *Parch*.\n",
    "\n",
    "We can change the script slightly, to include those new input features. But we can do better, we can use cross-validation to estimate what will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.755556, mean=0.755556, se=NaN\n",
      "CV  2:  acc=0.696629, mean=0.726092, se=0.041667\n",
      "CV  3:  acc=0.842697, mean=0.764960, se=0.073486\n",
      "CV  4:  acc=0.820225, mean=0.778777, se=0.066058\n",
      "CV  5:  acc=0.797753, mean=0.782572, se=0.057834\n",
      "CV  6:  acc=0.775281, mean=0.781357, se=0.051814\n",
      "CV  7:  acc=0.842697, mean=0.790119, se=0.052676\n",
      "CV  8:  acc=0.786517, mean=0.789669, se=0.048785\n",
      "CV  9:  acc=0.752809, mean=0.785574, se=0.047259\n",
      "CV 10:  acc=0.797753, mean=0.786792, se=0.044723\n",
      "==============\n",
      "Mean accuracy:0.786792\n",
      "SE: 0.044723     (Standard error)\n",
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.777778, mean=0.777778, se=NaN\n",
      "CV  2:  acc=0.842697, mean=0.810237, se=0.045905\n",
      "CV  3:  acc=0.741573, mean=0.787349, se=0.051237\n",
      "CV  4:  acc=0.797753, mean=0.789950, se=0.042157\n",
      "CV  5:  acc=0.808989, mean=0.793758, se=0.037489\n",
      "CV  6:  acc=0.775281, mean=0.790678, se=0.034369\n",
      "CV  7:  acc=0.808989, mean=0.793294, se=0.032128\n",
      "CV  8:  acc=0.820225, mean=0.796660, se=0.031232\n",
      "CV  9:  acc=0.775281, mean=0.794285, se=0.030071\n",
      "CV 10:  acc=0.775281, mean=0.792385, se=0.028982\n",
      "==============\n",
      "Mean accuracy:0.792385\n",
      "SE: 0.028982     (Standard error)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7923845193508114"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTree tree = CTree.newCART();\n",
    "CEvaluation.cv(train.mapVars(\"Survived,Sex,Pclass,Embarked\"),\"Survived\", tree, 10);\n",
    "CEvaluation.cv(train.mapVars(\"Survived,Sex,Pclass,Embarked,Age,Fare,SibSp,Parch\"),\"Survived\", tree, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the 10-crossfold estimator of the accuracy has dropped with a large quantity. What happens? We can have an idea if we take a look at the learned tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTree model\n",
      "================\n",
      "\n",
      "Description:\n",
      "CTree {varSelector=VarSelector[ALL];\n",
      "minCount=1;\n",
      "maxDepth=-1;\n",
      "tests=BINARY:BinaryBinary,DOUBLE:NumericBinary,NOMINAL:NominalBinary,INT:NumericBinary;\n",
      "func=GiniGain;\n",
      "split=ToAllWeighted;\n",
      "}\n",
      "\n",
      "Capabilities:\n",
      "types inputs/targets: BINARY,INT,NOMINAL,DOUBLE/NOMINAL\n",
      "counts inputs/targets: [1,1000000] / [1,1]\n",
      "missing inputs/targets: true/false\n",
      "\n",
      "Learned model:\n",
      "input vars: \n",
      " 0.      Sex : NOMINAL  | 3.   Age : DOUBLE  | 6. Parch : DOUBLE  |\n",
      " 1.   Pclass : NOMINAL  | 4.  Fare : DOUBLE  |                     \n",
      " 2. Embarked : NOMINAL  | 5. SibSp : DOUBLE  |                     \n",
      "\n",
      "target vars:\n",
      "> Survived : NOMINAL [?,0,1]\n",
      "\n",
      "\n",
      "total number of nodes: 511\n",
      "total number of leaves: 256\n",
      "description:\n",
      "split, n/err, classes (densities) [* if is leaf / purity if not]\n",
      "\n",
      "|- 0. root    891/342 0 (0.616 0.384 ) [0.5731486]\n",
      "|   |- 1. Age <= 37.5    703/271 0 (0.608 0.392 ) [0.6304902]\n",
      "|   |   |- 3. Age <= 27.5    514/193 0 (0.606 0.394 ) [0.11952]\n",
      "|   |   |   |- 7. Sex = 'female'    186/55 1 (0.291 0.709 ) [0.0265208]\n",
      "|   |   |   |   |- 15. SibSp <= 2.5    167/40 1 (0.24 0.76 ) [0.021889]\n",
      "|   |   |   |   |   |- 31. Fare <= 18.375    94/32 1 (0.347 0.653 ) [0.0134056]\n",
      "|   |   |   |   |   |   |- 57. Fare <= 17.25    92/30 1 (0.329 0.671 ) [0]\n",
      "|   |   |   |   |   |   |   |- 101. Fare <= 6.9875    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 102. Fare > 6.9875    91/29 1 (0.32 0.68 ) [0.0153622]\n",
      "|   |   |   |   |   |   |   |   |- 155. Fare <= 7.7625    26/5 1 (0.16 0.84 ) [0.0142375]\n",
      "|   |   |   |   |   |   |   |   |   |- 205. Fare <= 7.5229    6/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 206. Fare > 7.5229    20/5 1 (0.22 0.78 ) [0.0025643]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 263. Fare <= 7.6396    3/2 1 (0.486 0.514 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 315. Fare <= 7.5896    2/1 1 (0.321 0.679 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 316. Fare > 7.5896    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 264. Fare > 7.6396    17/3 1 (0.174 0.826 ) [0.0171058]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 317. Fare <= 7.74375    4/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 318. Fare > 7.74375    13/3 1 (0.236 0.764 ) *\n",
      "|   |   |   |   |   |   |   |   |- 156. Fare > 7.7625    65/24 1 (0.372 0.628 ) [0.029538]\n",
      "|   |   |   |   |   |   |   |   |   |- 207. Fare <= 10.48125    28/14 0 (0.522 0.478 ) [0.0561556]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 265. Fare <= 8.0396    17/5 1 (0.348 0.652 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 319. Fare <= 7.78125    3/1 0 (0.667 0.333 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 320. Fare > 7.78125    14/3 1 (0.264 0.736 ) [0.012641]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 365. Fare <= 7.9021    9/1 1 (0.157 0.843 ) [0.0086181]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 403. Fare <= 7.8667    5/1 1 (0.254 0.746 ) [0.0174789]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 441. Fare <= 7.8417    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 442. Fare > 7.8417    3/1 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 404. Fare > 7.8667    4/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 366. Fare > 7.9021    5/2 1 (0.4 0.6 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 405. Fare <= 7.9771    4/2 0 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 406. Fare > 7.9771    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 266. Fare > 8.0396    11/2 0 (0.788 0.212 ) [0.0311425]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 321. Fare <= 9.1    5/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 322. Fare > 9.1    6/2 0 (0.667 0.333 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 367. Fare <= 9.5875    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 368. Fare > 9.5875    5/1 0 (0.8 0.2 ) [0.0533333]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 407. Fare <= 9.8396    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 408. Fare > 9.8396    2/1 0 (0.5 0.5 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 443. Fare <= 10.1521    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 444. Fare > 10.1521    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 208. Fare > 10.48125    37/10 1 (0.261 0.739 ) [0.0406721]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 267. Fare <= 14.15625    18/2 1 (0.114 0.886 ) [0.0054325]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 323. Fare <= 10.825    4/1 1 (0.25 0.75 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 369. Fare <= 10.50835    3/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 370. Fare > 10.50835    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 324. Fare > 10.825    14/1 1 (0.074 0.926 ) [0.0075374]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 371. Fare <= 12.7375    8/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 372. Fare > 12.7375    6/1 1 (0.167 0.833 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 409. Fare <= 13.20835    3/1 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 410. Fare > 13.20835    3/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 268. Fare > 14.15625    19/8 1 (0.434 0.566 ) [0.1328966]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 325. Fare <= 15.3729    9/2 0 (0.73 0.27 ) [0.018183]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 373. Fare <= 14.8729    7/2 0 (0.664 0.336 ) [0.0065955]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 411. Fare <= 14.47915    6/1 0 (0.798 0.202 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 445. Fare <= 14.45625    4/1 0 (0.712 0.288 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 446. Fare > 14.45625    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 412. Fare > 14.47915    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 374. Fare > 14.8729    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 326. Fare > 15.3729    10/1 1 (0.136 0.864 ) [0.0180424]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 375. Fare <= 15.975    5/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 376. Fare > 15.975    5/1 1 (0.254 0.746 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 413. Fare <= 16.4    3/2 0 (0.514 0.486 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 414. Fare > 16.4    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |- 58. Fare > 17.25    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |- 32. Fare > 18.375    73/8 1 (0.115 0.885 ) [0.0062409]\n",
      "|   |   |   |   |   |   |- 59. Fare <= 149.0354    66/6 1 (0.094 0.906 ) [0.0072461]\n",
      "|   |   |   |   |   |   |   |- 103. Fare <= 36.6875    35/6 1 (0.172 0.828 ) [0.0399907]\n",
      "|   |   |   |   |   |   |   |   |- 157. Fare <= 33.6875    33/4 1 (0.116 0.884 ) [0.0076437]\n",
      "|   |   |   |   |   |   |   |   |   |- 209. Fare <= 26.125    22/4 1 (0.179 0.821 ) [0.0223973]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 269. Fare <= 20.25    6/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 270. Fare > 20.25    16/4 1 (0.26 0.74 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 327. Fare <= 21.5125    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 328. Fare > 21.5125    15/3 1 (0.2 0.8 ) [0.0374904]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 377. Fare <= 23.35    6/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 378. Fare > 23.35    9/3 1 (0.311 0.689 ) [0.0599432]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 415. Fare <= 25.075    3/1 0 (0.757 0.243 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 447. Fare <= 23.8    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 448. Fare > 23.8    2/1 0 (0.679 0.321 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 416. Fare > 25.075    6/1 1 (0.167 0.833 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 210. Fare > 26.125    11/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |- 158. Fare > 33.6875    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 104. Fare > 36.6875    31/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |- 60. Fare > 149.0354    7/2 1 (0.286 0.714 ) [0]\n",
      "|   |   |   |   |   |   |   |- 105. Fare <= 181.44375    3/1 0 (0.667 0.333 ) *\n",
      "|   |   |   |   |   |   |   |- 106. Fare > 181.44375    4/0 1 (0 1 ) *\n",
      "|   |   |   |   |- 16. SibSp > 2.5    19/4 0 (0.747 0.253 ) [0.1615179]\n",
      "|   |   |   |   |   |- 33. Pclass = '1'    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |- 34. Pclass != '1'    17/2 0 (0.855 0.145 ) [0]\n",
      "|   |   |   |   |   |   |- 61. SibSp <= 3.5    7/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 62. SibSp > 3.5    10/2 0 (0.762 0.238 ) [0]\n",
      "|   |   |   |   |   |   |   |- 107. Fare <= 19.6    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 108. Fare > 19.6    9/1 0 (0.865 0.135 ) [0]\n",
      "|   |   |   |   |   |   |   |   |- 159. Fare <= 31.33125    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 160. Fare > 31.33125    5/1 0 (0.707 0.293 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 211. Fare <= 39.14375    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 212. Fare > 39.14375    4/0 0 (1 0 ) *\n",
      "|   |   |   |- 8. Sex != 'female'    328/62 0 (0.796 0.204 ) [0.0219003]\n",
      "|   |   |   |   |- 17. Fare <= 15.1729    216/25 0 (0.873 0.127 ) [0.0009955]\n",
      "|   |   |   |   |   |- 35. Fare <= 7.9104    125/11 0 (0.899 0.101 ) [0.0054684]\n",
      "|   |   |   |   |   |   |- 63. Fare <= 7.7979    90/11 0 (0.859 0.141 ) [0.0077829]\n",
      "|   |   |   |   |   |   |   |- 109. Fare <= 7.7854    85/9 0 (0.88 0.12 ) [0.0030538]\n",
      "|   |   |   |   |   |   |   |   |- 161. Fare <= 7.2396    43/6 0 (0.826 0.174 ) [0.0055094]\n",
      "|   |   |   |   |   |   |   |   |   |- 213. Fare <= 7.13335    24/2 0 (0.89 0.11 ) [0.0037155]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 271. Fare <= 7.0125    16/2 0 (0.813 0.187 ) [0.0773044]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 329. Fare <= 6.9625    15/1 0 (0.897 0.103 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 379. Fare <= 2.00625    10/1 0 (0.827 0.173 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 380. Fare > 2.00625    5/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 330. Fare > 6.9625    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 272. Fare > 7.0125    8/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 214. Fare > 7.13335    19/4 0 (0.737 0.263 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 273. Fare <= 7.18335    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 274. Fare > 7.18335    18/3 0 (0.797 0.203 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 331. Fare <= 7.2271    7/1 0 (0.771 0.229 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 332. Fare > 7.2271    11/2 0 (0.812 0.188 ) *\n",
      "|   |   |   |   |   |   |   |   |- 162. Fare > 7.2396    42/3 0 (0.936 0.064 ) [0.0094103]\n",
      "|   |   |   |   |   |   |   |   |   |- 215. Fare <= 7.7625    33/1 0 (0.979 0.021 ) [0.001876]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 275. Fare <= 7.74585    21/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 276. Fare > 7.74585    12/1 0 (0.924 0.076 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 216. Fare > 7.7625    9/2 0 (0.815 0.185 ) *\n",
      "|   |   |   |   |   |   |   |- 110. Fare > 7.7854    5/2 0 (0.6 0.4 ) *\n",
      "|   |   |   |   |   |   |- 64. Fare > 7.7979    35/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |- 36. Fare > 7.9104    91/14 0 (0.841 0.159 ) [0.001715]\n",
      "|   |   |   |   |   |   |- 65. Fare <= 12.7375    68/11 0 (0.823 0.177 ) [0.0169745]\n",
      "|   |   |   |   |   |   |   |- 111. Fare <= 11.9875    67/10 0 (0.837 0.163 ) [0.003925]\n",
      "|   |   |   |   |   |   |   |   |- 163. Fare <= 10.81665    61/8 0 (0.856 0.144 ) [0.0067363]\n",
      "|   |   |   |   |   |   |   |   |   |- 217. Fare <= 8.6875    43/7 0 (0.816 0.184 ) [0.0011045]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 277. Fare <= 8.4875    34/5 0 (0.832 0.168 ) [0.0023753]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 333. Fare <= 8.1354    30/5 0 (0.807 0.193 ) [0.0013444]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 381. Fare <= 8.08125    29/4 0 (0.824 0.176 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 417. Fare <= 7.9875    4/1 0 (0.75 0.25 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 418. Fare > 7.9875    25/3 0 (0.839 0.161 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 382. Fare > 8.08125    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 334. Fare > 8.1354    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 278. Fare > 8.4875    9/2 0 (0.764 0.236 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 335. Fare <= 8.5896    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 336. Fare > 8.5896    8/1 0 (0.866 0.134 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 218. Fare > 8.6875    18/1 0 (0.941 0.059 ) [0.009896]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 279. Fare <= 10.3354    12/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 280. Fare > 10.3354    6/1 0 (0.833 0.167 ) *\n",
      "|   |   |   |   |   |   |   |   |- 164. Fare > 10.81665    6/2 0 (0.667 0.333 ) [0.1777778]\n",
      "|   |   |   |   |   |   |   |   |   |- 219. Fare <= 11.37085    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 220. Fare > 11.37085    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 112. Fare > 11.9875    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |- 66. Fare > 12.7375    23/3 0 (0.899 0.101 ) [0]\n",
      "|   |   |   |   |   |   |   |- 113. Fare <= 13.43125    12/1 0 (0.959 0.041 ) *\n",
      "|   |   |   |   |   |   |   |- 114. Fare > 13.43125    11/2 0 (0.812 0.188 ) [0]\n",
      "|   |   |   |   |   |   |   |   |- 165. Fare <= 14.15835    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |- 166. Fare > 14.15835    10/1 0 (0.864 0.136 ) [0.0137769]\n",
      "|   |   |   |   |   |   |   |   |   |- 221. Fare <= 14.47915    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 222. Fare > 14.47915    7/1 0 (0.795 0.205 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 281. Fare <= 14.7729    4/1 0 (0.66 0.34 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 282. Fare > 14.7729    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |- 18. Fare > 15.1729    112/37 0 (0.651 0.349 ) [0.0088957]\n",
      "|   |   |   |   |   |- 37. Fare <= 16    8/3 1 (0.264 0.736 ) [0.0298367]\n",
      "|   |   |   |   |   |   |- 67. Fare <= 15.62085    5/2 0 (0.6 0.4 ) [0]\n",
      "|   |   |   |   |   |   |   |- 115. Fare <= 15.3729    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 116. Fare > 15.3729    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 68. Fare > 15.62085    3/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |- 38. Fare > 16    104/32 0 (0.675 0.325 ) [0.0152534]\n",
      "|   |   |   |   |   |   |- 69. SibSp <= 1.5    72/29 0 (0.558 0.442 ) [0.0176639]\n",
      "|   |   |   |   |   |   |   |- 117. Fare <= 18.275    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 118. Fare > 18.275    68/29 0 (0.529 0.471 ) [0.0216471]\n",
      "|   |   |   |   |   |   |   |   |- 167. Fare <= 181.525    64/29 0 (0.502 0.498 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 223. Fare <= 18.76875    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 224. Fare > 18.76875    62/27 0 (0.522 0.478 ) [0.0207878]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 283. Fare <= 28.3604    23/6 0 (0.682 0.318 ) [0.0108676]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 337. Fare <= 27.1354    21/6 0 (0.663 0.337 ) [0.0074791]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 383. Fare <= 20.3875    6/1 0 (0.798 0.202 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 419. Fare <= 19.3771    2/1 1 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 420. Fare > 19.3771    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 384. Fare > 20.3875    15/5 0 (0.604 0.396 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 421. Fare <= 20.55    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 422. Fare > 20.55    14/4 0 (0.663 0.337 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 449. Fare <= 22.0125    2/1 0 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 450. Fare > 22.0125    12/3 0 (0.702 0.298 ) [0.036435]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 469. Fare <= 25.9625    4/0 0 (1 0 ) *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 470. Fare > 25.9625    8/3 0 (0.615 0.385 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 483. Fare <= 26.275    6/2 0 (0.635 0.365 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 484. Fare > 26.275    2/1 1 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 338. Fare > 27.1354    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 284. Fare > 28.3604    39/18 1 (0.436 0.564 ) [0.0390194]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 339. Fare <= 30.5979    6/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 340. Fare > 30.5979    33/15 0 (0.507 0.493 ) [0.0374853]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 385. Fare <= 35.25    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 386. Fare > 35.25    29/14 1 (0.459 0.541 ) [0.0162161]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 423. Fare <= 80.52915    22/10 0 (0.527 0.473 ) [0.0276216]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 451. Fare <= 68.42915    17/8 1 (0.42 0.58 ) [0.0729198]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 471. Fare <= 54.27085    11/4 0 (0.585 0.415 ) [0.0409115]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 485. Fare <= 38.3021    4/1 1 (0.288 0.712 ) [0.0261026]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 497. Fare <= 36.8771    3/1 1 (0.405 0.595 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 507. Fare <= 36.125    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 508. Fare > 36.125    2/1 0 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 498. Fare > 36.8771    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 486. Fare > 38.3021    7/1 0 (0.795 0.205 ) [0.0818126]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 499. Fare <= 52.55    5/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 500. Fare > 52.55    2/1 1 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 472. Fare > 54.27085    6/1 1 (0.107 0.893 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 487. Fare <= 55.96875    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 488. Fare > 55.96875    5/1 1 (0.138 0.862 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 501. Fare <= 59.92705    4/1 1 (0.195 0.805 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 502. Fare > 59.92705    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 452. Fare > 68.42915    5/1 0 (0.8 0.2 ) [0.0533333]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 473. Fare <= 77.00835    3/1 0 (0.667 0.333 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 489. Fare <= 75.1146    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 490. Fare > 75.1146    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 474. Fare > 77.00835    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 424. Fare > 80.52915    7/2 1 (0.286 0.714 ) [0.0272109]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 453. Fare <= 99.9896    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 454. Fare > 99.9896    5/2 1 (0.4 0.6 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 475. Fare <= 109.89165    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 476. Fare > 109.89165    4/1 1 (0.25 0.75 ) [0.0416667]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 491. Fare <= 127.81665    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 492. Fare > 127.81665    2/1 1 (0.5 0.5 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 503. Fare <= 143.59165    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 504. Fare > 143.59165    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |- 168. Fare > 181.525    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 70. SibSp > 1.5    32/3 0 (0.913 0.087 ) [0.0028599]\n",
      "|   |   |   |   |   |   |   |- 119. Fare <= 39.34375    16/3 0 (0.829 0.171 ) [0.0828944]\n",
      "|   |   |   |   |   |   |   |   |- 169. Fare <= 31.33125    13/1 0 (0.959 0.041 ) [0.0009449]\n",
      "|   |   |   |   |   |   |   |   |   |- 225. Fare <= 23.7    4/1 0 (0.84 0.16 ) [0.1089163]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 285. Fare <= 22.4646    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 286. Fare > 22.4646    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 226. Fare > 23.7    9/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 170. Fare > 31.33125    3/1 1 (0.333 0.667 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 227. Fare <= 35.19375    2/1 0 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 228. Fare > 35.19375    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 120. Fare > 39.34375    16/0 0 (1 0 ) *\n",
      "|   |   |- 4. Age > 27.5    366/130 0 (0.611 0.389 ) [0.1628202]\n",
      "|   |   |   |- 9. Sex = 'female'    116/28 1 (0.201 0.799 ) [0.0497845]\n",
      "|   |   |   |   |- 19. Fare <= 10.48125    30/17 0 (0.6 0.4 ) [0.0738233]\n",
      "|   |   |   |   |   |- 39. Fare <= 7.8875    22/6 1 (0.419 0.581 ) [0.0275257]\n",
      "|   |   |   |   |   |   |- 71. Fare <= 7.8667    19/6 1 (0.471 0.529 ) [0.049508]\n",
      "|   |   |   |   |   |   |   |- 121. Fare <= 7.8417    18/5 1 (0.374 0.626 ) [0.0141699]\n",
      "|   |   |   |   |   |   |   |   |- 171. Fare <= 7.3896    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |- 172. Fare > 7.3896    16/5 1 (0.414 0.586 ) [0.0386055]\n",
      "|   |   |   |   |   |   |   |   |   |- 229. Fare <= 7.68125    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 230. Fare > 7.68125    14/3 1 (0.344 0.656 ) [0.0150327]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 287. Fare <= 7.74375    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 288. Fare > 7.74375    12/3 1 (0.391 0.609 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 341. Fare <= 7.76875    10/3 1 (0.452 0.548 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 342. Fare > 7.76875    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 122. Fare > 7.8417    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 72. Fare > 7.8667    3/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |- 40. Fare > 7.8875    8/1 0 (0.827 0.173 ) [0.0267206]\n",
      "|   |   |   |   |   |   |- 73. Fare <= 8.6729    5/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 74. Fare > 8.6729    3/1 0 (0.667 0.333 ) [0]\n",
      "|   |   |   |   |   |   |   |- 123. Fare <= 9.1354    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 124. Fare > 9.1354    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |- 20. Fare > 10.48125    86/15 1 (0.12 0.88 ) [0.0139009]\n",
      "|   |   |   |   |   |- 41. SibSp <= 5.5    83/12 1 (0.109 0.891 ) [0.0149254]\n",
      "|   |   |   |   |   |   |- 75. Fare <= 25.73335    44/12 1 (0.218 0.782 ) [0.0189955]\n",
      "|   |   |   |   |   |   |   |- 125. Fare <= 13.7    14/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 126. Fare > 13.7    30/12 1 (0.376 0.624 ) [0.0580713]\n",
      "|   |   |   |   |   |   |   |   |- 173. Fare <= 14.85205    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 174. Fare > 14.85205    27/9 1 (0.319 0.681 ) [0.0449441]\n",
      "|   |   |   |   |   |   |   |   |   |- 231. Fare <= 24.075    22/5 1 (0.241 0.759 ) [0.0157085]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 289. Fare <= 19.125    11/3 1 (0.344 0.656 ) [0.0212841]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 343. Fare <= 17.7    10/2 1 (0.226 0.774 ) [0.0001693]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 387. Fare <= 15.675    6/2 1 (0.413 0.587 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 425. Fare <= 15.3729    2/1 1 (0.209 0.791 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 426. Fare > 15.3729    4/3 0 (0.557 0.443 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 388. Fare > 15.675    4/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 344. Fare > 17.7    1/0 0 (1 0 ) *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   |   |   |   |   |   |   |   |   |   |- 290. Fare > 19.125    11/2 1 (0.157 0.843 ) [0.0162595]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 345. Fare <= 21.0375    4/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 346. Fare > 21.0375    7/2 1 (0.312 0.688 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 389. Fare <= 21.71665    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 390. Fare > 21.71665    6/1 1 (0.087 0.913 ) [0.0149778]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 427. Fare <= 23.35    4/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 428. Fare > 23.35    2/1 1 (0.209 0.791 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 455. Fare <= 23.725    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 456. Fare > 23.725    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 232. Fare > 24.075    5/1 0 (0.871 0.129 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 291. Fare <= 24.80835    2/1 0 (0.791 0.209 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 292. Fare > 24.80835    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 76. Fare > 25.73335    39/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |- 42. SibSp > 5.5    3/0 0 (1 0 ) *\n",
      "|   |   |   |- 10. Sex != 'female'    250/42 0 (0.81 0.19 ) [0.0351861]\n",
      "|   |   |   |   |- 21. Fare <= 26.26875    193/20 0 (0.888 0.112 ) [0.0039067]\n",
      "|   |   |   |   |   |- 43. Fare <= 7.74375    43/1 0 (0.987 0.013 ) [0.0003305]\n",
      "|   |   |   |   |   |   |- 77. Fare <= 7.2271    24/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 78. Fare > 7.2271    19/1 0 (0.967 0.033 ) [0]\n",
      "|   |   |   |   |   |   |   |- 127. Fare <= 7.2396    8/1 0 (0.926 0.074 ) *\n",
      "|   |   |   |   |   |   |   |- 128. Fare > 7.2396    11/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |- 44. Fare > 7.74375    150/19 0 (0.868 0.132 ) [0.002296]\n",
      "|   |   |   |   |   |   |- 79. Fare <= 15.3729    118/17 0 (0.847 0.153 ) [0.0054628]\n",
      "|   |   |   |   |   |   |   |- 129. Fare <= 15.1729    116/15 0 (0.853 0.147 ) [0.0010712]\n",
      "|   |   |   |   |   |   |   |   |- 175. Fare <= 14.13125    110/15 0 (0.848 0.152 ) [0.0025787]\n",
      "|   |   |   |   |   |   |   |   |   |- 233. Fare <= 13.68125    109/14 0 (0.851 0.149 ) [0.0010504]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 293. Fare <= 12.9375    98/11 0 (0.863 0.137 ) [0.0021493]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 347. Fare <= 10    89/11 0 (0.841 0.159 ) [0.0065469]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 391. Fare <= 9.49165    83/9 0 (0.864 0.136 ) [0.0027067]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 429. Fare <= 7.9875    54/7 0 (0.831 0.169 ) [0.0011343]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 457. Fare <= 7.9104    48/5 0 (0.868 0.132 ) [0.0037938]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 477. Fare <= 7.8646    23/4 0 (0.801 0.199 ) [0.025507]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 493. Fare <= 7.8417    21/3 0 (0.857 0.143 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 505. Fare <= 7.7625    14/2 0 (0.786 0.214 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 506. Fare > 7.7625    7/1 0 (0.945 0.055 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 509. Fare <= 7.7854    5/1 0 (0.925 0.075 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 510. Fare > 7.7854    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 494. Fare > 7.8417    2/1 1 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 478. Fare > 7.8646    25/1 0 (0.928 0.072 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 495. Fare <= 7.8854    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 496. Fare > 7.8854    24/1 0 (0.923 0.077 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 458. Fare > 7.9104    6/2 0 (0.667 0.333 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 430. Fare > 7.9875    29/2 0 (0.927 0.073 ) [0.0003683]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 459. Fare <= 8.2375    22/2 0 (0.898 0.102 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 479. Fare <= 8.08125    21/1 0 (0.918 0.082 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 480. Fare > 8.08125    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 460. Fare > 8.2375    7/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 392. Fare > 9.49165    6/2 0 (0.62 0.38 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 348. Fare > 10    9/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 294. Fare > 12.9375    11/3 0 (0.779 0.221 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 349. Fare <= 13.25    10/3 0 (0.756 0.244 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 350. Fare > 13.25    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 234. Fare > 13.68125    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |- 176. Fare > 14.13125    6/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 130. Fare > 15.1729    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |- 80. Fare > 15.3729    32/2 0 (0.942 0.058 ) [0.008168]\n",
      "|   |   |   |   |   |   |   |- 131. Fare <= 25.9625    25/1 0 (0.983 0.017 ) [0.0013903]\n",
      "|   |   |   |   |   |   |   |   |- 177. Fare <= 22.8875    17/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 178. Fare > 22.8875    8/1 0 (0.926 0.074 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 235. Fare <= 23.35    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 236. Fare > 23.35    7/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 132. Fare > 25.9625    7/1 0 (0.84 0.16 ) [0]\n",
      "|   |   |   |   |   |   |   |   |- 179. Fare <= 26.125    6/1 0 (0.81 0.19 ) *\n",
      "|   |   |   |   |   |   |   |   |- 180. Fare > 26.125    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |- 22. Fare > 26.26875    57/22 0 (0.572 0.428 ) [0.0539538]\n",
      "|   |   |   |   |   |- 45. Fare <= 27.1354    8/1 1 (0.041 0.959 ) [0.0014514]\n",
      "|   |   |   |   |   |   |- 81. Fare <= 26.46875    3/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |- 82. Fare > 26.46875    5/1 1 (0.075 0.925 ) *\n",
      "|   |   |   |   |   |- 46. Fare > 27.1354    49/15 0 (0.677 0.323 ) [0.0491367]\n",
      "|   |   |   |   |   |   |- 83. Fare <= 101.0854    44/12 0 (0.741 0.259 ) [0.0215043]\n",
      "|   |   |   |   |   |   |   |- 133. Fare <= 61.8    36/12 0 (0.687 0.313 ) [0.0617443]\n",
      "|   |   |   |   |   |   |   |   |- 181. Fare <= 52.2771    27/6 0 (0.825 0.175 ) [0.0156066]\n",
      "|   |   |   |   |   |   |   |   |   |- 237. Fare <= 36.2521    18/6 0 (0.731 0.269 ) [0.1225561]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 295. Fare <= 35.25    16/4 0 (0.823 0.177 ) [0.0336904]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 351. Fare <= 30.2854    10/2 0 (0.925 0.075 ) [0.0031117]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 393. Fare <= 28.725    5/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 394. Fare > 28.725    5/2 0 (0.85 0.15 ) [0.0039278]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 431. Fare <= 30.0354    4/2 0 (0.791 0.209 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 461. Fare <= 29.85    2/1 0 (0.791 0.209 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 462. Fare > 29.85    2/1 0 (0.791 0.209 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 432. Fare > 30.0354    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 352. Fare > 30.2854    6/2 0 (0.587 0.413 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 395. Fare <= 30.5979    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 396. Fare > 30.5979    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 296. Fare > 35.25    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 238. Fare > 36.2521    9/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 182. Fare > 52.2771    9/3 1 (0.333 0.667 ) [0.0383531]\n",
      "|   |   |   |   |   |   |   |   |   |- 239. Fare <= 56.7479    8/3 1 (0.391 0.609 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 297. Fare <= 52.8271    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 298. Fare > 52.8271    7/3 1 (0.472 0.528 ) [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   |   |   |   |   |   |   |   |   |   |   |- 353. Fare <= 54.7979    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 354. Fare > 54.7979    6/2 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 240. Fare > 56.7479    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 134. Fare > 61.8    8/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 84. Fare > 101.0854    5/2 1 (0.15 0.85 ) [0.0177907]\n",
      "|   |   |   |   |   |   |   |- 135. Fare <= 369.9271    3/2 1 (0.346 0.654 ) [0]\n",
      "|   |   |   |   |   |   |   |   |- 183. Fare <= 170.8896    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |- 184. Fare > 170.8896    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 136. Fare > 369.9271    2/0 1 (0 1 ) *\n",
      "|   |- 2. Age > 37.5    365/123 0 (0.639 0.361 ) [0.1561569]\n",
      "|   |   |- 5. Sex = 'female'    118/32 1 (0.247 0.753 ) [0.0575632]\n",
      "|   |   |   |- 11. Fare <= 49.1896    76/29 1 (0.408 0.592 ) [0.0579414]\n",
      "|   |   |   |   |- 23. Pclass = '2'    18/3 1 (0.182 0.818 ) [0.0102224]\n",
      "|   |   |   |   |   |- 47. Fare <= 13.25    7/2 1 (0.319 0.681 ) [0]\n",
      "|   |   |   |   |   |   |- 85. Fare <= 11.425    3/1 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |   |- 86. Fare > 11.425    4/1 1 (0.306 0.694 ) [0]\n",
      "|   |   |   |   |   |   |   |- 137. Fare <= 12.675    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 138. Fare > 12.675    3/1 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |- 48. Fare > 13.25    11/1 1 (0.097 0.903 ) [0.0121258]\n",
      "|   |   |   |   |   |   |- 87. Fare <= 24.5    5/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |- 88. Fare > 24.5    6/1 1 (0.19 0.81 ) [0]\n",
      "|   |   |   |   |   |   |   |- 139. Fare <= 26.125    3/1 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |   |   |- 140. Fare > 26.125    3/0 1 (0 1 ) *\n",
      "|   |   |   |   |- 24. Pclass != '2'    58/32 0 (0.536 0.464 ) [0.0279381]\n",
      "|   |   |   |   |   |- 49. Fare <= 27.8104    49/19 1 (0.429 0.571 ) [0.0565474]\n",
      "|   |   |   |   |   |   |- 89. Fare <= 25.69795    45/26 0 (0.534 0.466 ) [0.0256494]\n",
      "|   |   |   |   |   |   |   |- 141. Fare <= 7.9646    21/5 1 (0.328 0.672 ) [0.0197025]\n",
      "|   |   |   |   |   |   |   |   |- 185. Fare <= 7.76875    16/5 1 (0.415 0.585 ) [0.0193373]\n",
      "|   |   |   |   |   |   |   |   |   |- 241. Fare <= 7.3896    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 242. Fare > 7.3896    14/5 1 (0.464 0.536 ) [0.0363419]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 299. Fare <= 7.68125    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 300. Fare > 7.68125    12/3 1 (0.392 0.608 ) [0.0222514]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 355. Fare <= 7.74375    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 356. Fare > 7.74375    10/3 1 (0.453 0.547 ) *\n",
      "|   |   |   |   |   |   |   |   |- 186. Fare > 7.76875    5/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 142. Fare > 7.9646    24/10 0 (0.663 0.337 ) [0.0502301]\n",
      "|   |   |   |   |   |   |   |   |- 187. Fare <= 15.3729    10/1 0 (0.821 0.179 ) [0.0303383]\n",
      "|   |   |   |   |   |   |   |   |   |- 243. Fare <= 12.02085    5/1 0 (0.642 0.358 ) [0.1014843]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 301. Fare <= 9.53125    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 302. Fare > 9.53125    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 244. Fare > 12.02085    5/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 188. Fare > 15.3729    14/5 1 (0.464 0.536 ) [0.0937093]\n",
      "|   |   |   |   |   |   |   |   |   |- 245. Fare <= 18.15625    5/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 246. Fare > 18.15625    9/4 0 (0.661 0.339 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 303. Fare <= 21.2854    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 304. Fare > 21.2854    8/4 0 (0.5 0.5 ) [0.3]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 357. Fare <= 24.80835    5/1 1 (0.2 0.8 ) [0.0533333]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 397. Fare <= 23.35    3/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 398. Fare > 23.35    2/1 0 (0.5 0.5 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 433. Fare <= 23.8    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 434. Fare > 23.8    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 358. Fare > 24.80835    3/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 90. Fare > 25.69795    4/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |- 50. Fare > 27.8104    9/2 0 (0.778 0.222 ) [0.0493827]\n",
      "|   |   |   |   |   |   |- 91. Fare <= 31.33125    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 92. Fare > 31.33125    5/2 0 (0.6 0.4 ) [0.18]\n",
      "|   |   |   |   |   |   |   |- 143. Fare <= 39.64375    3/1 1 (0.333 0.667 ) [0.1111111]\n",
      "|   |   |   |   |   |   |   |   |- 189. Fare <= 36.9875    2/1 0 (0.5 0.5 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 247. Fare <= 32.88125    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 248. Fare > 32.88125    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 190. Fare > 36.9875    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 144. Fare > 39.64375    2/0 0 (1 0 ) *\n",
      "|   |   |   |- 12. Fare > 49.1896    42/3 1 (0.024 0.976 ) [0.0198907]\n",
      "|   |   |   |   |- 25. SibSp <= 5    39/0 1 (0 1 ) *\n",
      "|   |   |   |   |- 26. SibSp > 5    3/0 0 (1 0 ) *\n",
      "|   |   |- 6. Sex != 'female'    247/37 0 (0.838 0.162 ) [0.0196887]\n",
      "|   |   |   |- 13. Fare <= 26.26875    167/14 0 (0.921 0.079 ) [0.0038356]\n",
      "|   |   |   |   |- 27. Fare <= 7.9104    84/3 0 (0.98 0.02 ) [0.0003777]\n",
      "|   |   |   |   |   |- 51. Fare <= 7.2271    28/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |- 52. Fare > 7.2271    56/3 0 (0.967 0.033 ) [0]\n",
      "|   |   |   |   |   |   |- 93. Fare <= 7.2396    6/1 0 (0.833 0.167 ) *\n",
      "|   |   |   |   |   |   |- 94. Fare > 7.2396    50/2 0 (0.976 0.024 ) [0.0004666]\n",
      "|   |   |   |   |   |   |   |- 145. Fare <= 7.8021    31/2 0 (0.964 0.036 ) [0.0019168]\n",
      "|   |   |   |   |   |   |   |   |- 191. Fare <= 7.7625    28/1 0 (0.98 0.02 ) [0.000672]\n",
      "|   |   |   |   |   |   |   |   |   |- 249. Fare <= 7.74375    13/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 250. Fare > 7.74375    15/1 0 (0.962 0.038 ) *\n",
      "|   |   |   |   |   |   |   |   |- 192. Fare > 7.7625    3/1 0 (0.828 0.172 ) *\n",
      "|   |   |   |   |   |   |   |- 146. Fare > 7.8021    19/0 0 (1 0 ) *\n",
      "|   |   |   |   |- 28. Fare > 7.9104    83/11 0 (0.877 0.123 ) [0]\n",
      "|   |   |   |   |   |- 53. Fare <= 7.9875    3/1 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |- 54. Fare > 7.9875    80/9 0 (0.909 0.091 ) [0.0043312]\n",
      "|   |   |   |   |   |   |- 95. Fare <= 23.35    65/9 0 (0.885 0.115 ) [0.0039673]\n",
      "|   |   |   |   |   |   |   |- 147. Fare <= 22.4646    64/8 0 (0.891 0.109 ) [0.0019103]\n",
      "|   |   |   |   |   |   |   |   |- 193. Fare <= 15.3729    55/8 0 (0.88 0.12 ) [0.0134471]\n",
      "|   |   |   |   |   |   |   |   |   |- 251. Fare <= 15.1729    53/6 0 (0.893 0.107 ) [0.0028778]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 305. Fare <= 13.93125    44/6 0 (0.874 0.126 ) [0.0042555]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 359. Fare <= 13.68125    43/5 0 (0.881 0.119 ) [0.0026458]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 399. Fare <= 10    28/2 0 (0.918 0.082 ) [0.0010786]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 435. Fare <= 8.25835    20/2 0 (0.879 0.121 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 463. Fare <= 8.08125    19/1 0 (0.902 0.098 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 464. Fare > 8.08125    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 436. Fare > 8.25835    8/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 400. Fare > 10    15/3 0 (0.841 0.159 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 437. Fare <= 11.425    3/1 0 (0.667 0.333 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 438. Fare > 11.425    12/2 0 (0.888 0.112 ) [0.0054322]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 465. Fare <= 13.25    10/2 0 (0.864 0.136 ) [0.0045015]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 481. Fare <= 12.7625    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 482. Fare > 12.7625    8/2 0 (0.826 0.174 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 466. Fare > 13.25    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 360. Fare > 13.68125    1/0 1 (0 1 ) *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   |   |   |   |   |   |   |   |   |   |- 306. Fare > 13.93125    9/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 252. Fare > 15.1729    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |- 194. Fare > 15.3729    9/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |- 148. Fare > 22.4646    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |- 96. Fare > 23.35    15/0 0 (1 0 ) *\n",
      "|   |   |   |- 14. Fare > 26.26875    80/23 0 (0.714 0.286 ) [0.0054363]\n",
      "|   |   |   |   |- 29. Pclass = '2'    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |- 30. Pclass != '2'    78/23 0 (0.704 0.296 ) [0]\n",
      "|   |   |   |   |   |- 55. SibSp <= 0.5    54/15 0 (0.749 0.251 ) [0.0348365]\n",
      "|   |   |   |   |   |   |- 97. Fare <= 31.6604    27/11 0 (0.605 0.395 ) [0]\n",
      "|   |   |   |   |   |   |   |- 149. Fare <= 26.41875    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 150. Fare > 26.41875    26/10 0 (0.636 0.364 ) [0.028739]\n",
      "|   |   |   |   |   |   |   |   |- 195. Fare <= 29.85    17/5 0 (0.735 0.265 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 253. Fare <= 27.1354    11/4 0 (0.657 0.343 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 254. Fare > 27.1354    6/1 0 (0.931 0.069 ) [0.0065114]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 307. Fare <= 29.1    4/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 308. Fare > 29.1    2/1 0 (0.792 0.208 ) *\n",
      "|   |   |   |   |   |   |   |   |- 196. Fare > 29.85    9/4 1 (0.417 0.583 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 255. Fare <= 30.25    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 256. Fare > 30.25    7/3 0 (0.527 0.473 ) [0.013144]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 309. Fare <= 30.8479    5/2 0 (0.642 0.358 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 361. Fare <= 30.5979    3/1 1 (0.442 0.558 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 362. Fare > 30.5979    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 310. Fare > 30.8479    2/1 1 (0.208 0.792 ) *\n",
      "|   |   |   |   |   |   |- 98. Fare > 31.6604    27/4 0 (0.905 0.095 ) [0.0052282]\n",
      "|   |   |   |   |   |   |   |- 151. Fare <= 37    8/2 0 (0.806 0.194 ) [0.1186296]\n",
      "|   |   |   |   |   |   |   |   |- 197. Fare <= 35.25    5/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 198. Fare > 35.25    3/1 1 (0.442 0.558 ) *\n",
      "|   |   |   |   |   |   |   |- 152. Fare > 37    19/2 0 (0.957 0.043 ) [0.0025035]\n",
      "|   |   |   |   |   |   |   |   |- 199. Fare <= 58.9375    11/2 0 (0.91 0.09 ) [0.0299855]\n",
      "|   |   |   |   |   |   |   |   |   |- 257. Fare <= 54.2479    8/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 258. Fare > 54.2479    3/1 1 (0.333 0.667 ) *\n",
      "|   |   |   |   |   |   |   |   |- 200. Fare > 58.9375    8/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |- 56. SibSp > 0.5    24/8 0 (0.62 0.38 ) [0.0144009]\n",
      "|   |   |   |   |   |   |- 99. Fare <= 41.6375    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |- 100. Fare > 41.6375    22/8 0 (0.58 0.42 ) [0.0227638]\n",
      "|   |   |   |   |   |   |   |- 153. Fare <= 59.0521    5/2 1 (0.4 0.6 ) [0.0133333]\n",
      "|   |   |   |   |   |   |   |   |- 201. Fare <= 56.4146    4/2 0 (0.5 0.5 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |- 259. Fare <= 54.2271    3/1 1 (0.333 0.667 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 311. Fare <= 52.2771    2/1 0 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 312. Fare > 52.2771    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 260. Fare > 54.2271    1/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 202. Fare > 56.4146    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |- 154. Fare > 59.0521    17/5 0 (0.644 0.356 ) [0.0433184]\n",
      "|   |   |   |   |   |   |   |   |- 203. Fare <= 73.8646    6/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |- 204. Fare > 73.8646    11/5 0 (0.545 0.455 ) [0.0595041]\n",
      "|   |   |   |   |   |   |   |   |   |- 261. Fare <= 79.425    2/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |- 262. Fare > 79.425    9/3 0 (0.667 0.333 ) [0.0277778]\n",
      "|   |   |   |   |   |   |   |   |   |   |- 313. Fare <= 86.2896    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |- 314. Fare > 86.2896    7/3 0 (0.571 0.429 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 363. Fare <= 89.5521    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |- 364. Fare > 89.5521    6/2 0 (0.667 0.333 ) [0.0277778]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 401. Fare <= 198.325    5/2 0 (0.6 0.4 ) [0.0133333]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 439. Fare <= 122.26665    4/1 0 (0.75 0.25 ) [0]\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 467. Fare <= 98.2125    2/1 0 (0.5 0.5 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |- 468. Fare > 98.2125    2/0 0 (1 0 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |- 440. Fare > 122.26665    1/0 1 (0 1 ) *\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |- 402. Fare > 198.325    1/0 0 (1 0 ) *\n"
     ]
    }
   ],
   "source": [
    "tree.fit(train.mapVars(\"Survived,Sex,Pclass,Embarked,Age,Fare,SibSp,Parch\"), \"Survived\");\n",
    "tree.printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice how large is the tree. Basically the tree was full grown and overfit the training data set too much. We can ask ourselves why that happens? Why it happens now, and did not happened when we had fewer inputs? The answer is that it happened also before. But it's consequences were not so drastic.\n",
    "\n",
    "The first tree used for training just $3$ input nominal features. Notice that all three features are nominal. The maximum number of groups which one can form is given by the product of the number of levels for each feature. This total maximal number is $2*3*3=18$. It practically exhausted the discrimination potential of those features. It did overfit in that reduced space of features. When we apply the model to the whole data set, the effect of exhaustion is not seen anymore.\n",
    "\n",
    "The second tree does the same thing, but this time in a richer space, with added input dimensions. Compared with the full feature space, we see the effect.\n",
    "\n",
    "There are two approaches to avoid overfit for a decision tree. The first approach is to stop learning up to the moment when we exhaust the data. The name for this approach is *early stop*. We can do that by specifying some parameters of the tree model:\n",
    "\n",
    "* Set a minimum number of instances for leaf node\n",
    "* Set a maximal depth for the tree\n",
    "* Not implemented yet, but easy to do: complexity threshold, maximal number of nodes in a tree\n",
    "\n",
    "The second approach is to prune the tree. Pruning procedure consists of growing the full tree and later on removing some nodes if they do not provide some type of gain. Currently we implemented only *reduced error pruning strategy*.\n",
    "\n",
    "We will test with 10-fold cross validation an early-stopping strategy to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.800000, mean=0.800000, se=NaN\n",
      "CV  2:  acc=0.741573, mean=0.770787, se=0.041314\n",
      "CV  3:  acc=0.775281, mean=0.772285, se=0.029328\n",
      "CV  4:  acc=0.797753, mean=0.778652, se=0.027122\n",
      "CV  5:  acc=0.786517, mean=0.780225, se=0.023750\n",
      "CV  6:  acc=0.786517, mean=0.781273, se=0.021398\n",
      "CV  7:  acc=0.775281, mean=0.780417, se=0.019664\n",
      "CV  8:  acc=0.842697, mean=0.788202, se=0.028571\n",
      "CV  9:  acc=0.831461, mean=0.793009, se=0.030367\n",
      "CV 10:  acc=0.808989, mean=0.794607, se=0.029073\n",
      "==============\n",
      "Mean accuracy:0.794607\n",
      "SE: 0.029073     (Standard error)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7946067415730337"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CEvaluation.cv(train.mapVars(\"Survived,Sex,Pclass,Embarked,Age,Fare,SibSp,Parch\"),\n",
    "\"Survived\", tree.withMaxDepth(12).withMinCount(4), 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I tried some values, just to show that we can do something about it, but the progress did not appear. We should try a different approach, and that is an ensemble. Next session contains directions on how to build such an ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. CForest model\n",
    "\n",
    "Random forests are well-known to work well when the irreducible error from the training data is high. This is probably the case of this Titanic data set. We have reasons to believe that this is the situation since it was a tragedy. A lot of random or not-so-expected things happened. That happened despite of the bravery and the sacrifice of the crew and others.\n",
    "\n",
    "Random forests are the invention of [Leo Breiman](https://en.wikipedia.org/wiki/Leo_Breiman). The first design was a joint effort together with [Adele Cutler](http://www.math.usu.edu/adele/). The base of random forests is bagging (or **b**ootstrapp **ag**gregation). On top of that, selecting just a random limited number of variables at each node is the core of the algorithm.\n",
    "\n",
    "We will work with random forests for now. This ensemble is mode robust and is capable of obtaining much better results than a single tree. At the same time we will introduce 10-fold cross validation to check our progress and estimate the error produced.\n",
    "\n",
    "In the beginning we will use 10-fold cross validation for estimating the accuracy on public leader board.\n",
    "\n",
    "We will test first with 10 fold cv the tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.666667, mean=0.666667, se=NaN\n",
      "CV  2:  acc=0.775281, mean=0.720974, se=0.076802\n",
      "CV  3:  acc=0.842697, mean=0.761548, se=0.088815\n",
      "CV  4:  acc=0.775281, mean=0.764981, se=0.072841\n",
      "CV  5:  acc=0.775281, mean=0.767041, se=0.063250\n",
      "CV  6:  acc=0.808989, mean=0.774032, se=0.059108\n",
      "CV  7:  acc=0.820225, mean=0.780631, se=0.056712\n",
      "CV  8:  acc=0.865169, mean=0.791199, se=0.060416\n",
      "CV  9:  acc=0.775281, mean=0.789430, se=0.056763\n",
      "CV 10:  acc=0.764045, mean=0.786891, se=0.054115\n",
      "==============\n",
      "Mean accuracy:0.786891\n",
      "SE: 0.054115     (Standard error)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7868913857677903"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CEvaluation.cv(train.mapVars(\"Survived,Sex,Pclass,Embarked\"), \"Survived\", CTree.newCART(), 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.1 Our first random forest\n",
    "\n",
    "The name of the random forest implementation is `CForest`. To build a new ensemble of trees, one have to instantiate it in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier rf = CForest.newRF();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of things which can be customized for a random forest. Among them one can change:\n",
    "\n",
    "* Number of trees for classification\n",
    "* Which kind of weak classifier to use (you can customize this customized accordingly, like any other classifier)\n",
    "* Number of threads in pool (if you want to use parallelism)\n",
    "* What to do after each running step\n",
    "\n",
    "Let's build one and use ore new cross validation procedure to estimate it's error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.733333, mean=0.733333, se=NaN\n",
      "CV  2:  acc=0.808989, mean=0.771161, se=0.053496\n",
      "CV  3:  acc=0.842697, mean=0.795006, se=0.056006\n",
      "CV  4:  acc=0.764045, mean=0.787266, se=0.048278\n",
      "CV  5:  acc=0.842697, mean=0.798352, se=0.048607\n",
      "CV  6:  acc=0.831461, mean=0.803870, se=0.045528\n",
      "CV  7:  acc=0.730337, mean=0.793365, se=0.049998\n",
      "CV  8:  acc=0.820225, mean=0.796723, se=0.047253\n",
      "CV  9:  acc=0.820225, mean=0.799334, se=0.044890\n",
      "CV 10:  acc=0.674157, mean=0.786816, se=0.057949\n",
      "==============\n",
      "Mean accuracy:0.786816\n",
      "SE: 0.057949     (Standard error)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7868164794007491"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomSource.setSeed(123);\n",
    "Frame tr = train.mapVars(\"Survived,Sex,Pclass,Embarked\");\n",
    "CForest rf = CForest.newRF().withRuns(100);\n",
    "CEvaluation.cv(tr, \"Survived\", rf, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, an identical output. This is due to the fact that our variables are already exhausted by the tree. It looks like an underfit. If one consider bias variance trade off, one can see this as high bias. We need to enrich our feature space to improve our performance.\n",
    "\n",
    "Let's be direct and test what would happen if we would use all our directly usable features? This time we will fit also the training data set, to see the distribution of the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.822222, mean=0.822222, se=NaN\n",
      "CV  2:  acc=0.853933, mean=0.838077, se=0.022423\n",
      "CV  3:  acc=0.876404, mean=0.850853, se=0.027222\n",
      "CV  4:  acc=0.842697, mean=0.848814, se=0.022598\n",
      "CV  5:  acc=0.775281, mean=0.834107, se=0.038268\n",
      "CV  6:  acc=0.842697, mean=0.835539, se=0.034407\n",
      "CV  7:  acc=0.764045, mean=0.825325, se=0.041433\n",
      "CV  8:  acc=0.831461, mean=0.826092, se=0.038421\n",
      "CV  9:  acc=0.842697, mean=0.827937, se=0.036363\n",
      "CV 10:  acc=0.719101, mean=0.817054, se=0.048579\n",
      "==============\n",
      "Mean accuracy:0.817054\n",
      "SE: 0.048579     (Standard error)\n",
      "> Confusion\n",
      "\n",
      " Ac\\Pr |    0    1 | total\n",
      " ----- |    -    - | -----\n",
      "     0 | >527   22 |   549\n",
      "     1 |   46 >296 |   342\n",
      " ----- |    -    - | -----\n",
      " total |  573  318 |   891\n",
      "\n",
      "\n",
      "Complete cases 891 from 891\n",
      "Acc: 0.9236813         (Accuracy )\n",
      "F1:  0.9393939         (F1 score / F-measure)\n",
      "MCC: 0.8378872         (Matthew correlation coefficient)\n",
      "Pre: 0.9197208         (Precision)\n",
      "Rec: 0.9599271         (Recall)\n",
      "G:   0.9396089         (G-measure)\n"
     ]
    }
   ],
   "source": [
    "RandomSource.setSeed(123);\n",
    "Frame tr = train.mapVars(\"Survived,Sex,Pclass,Embarked,Age,Fare,SibSp,Parch\");\n",
    "CForest rf = CForest.newRF().withRuns(100);\n",
    "CEvaluation.cv(tr, \"Survived\", rf, 10);\n",
    "\n",
    "rf.fit(tr, \"Survived\");\n",
    "CPrediction fit = rf.predict(test);\n",
    "new Confusion(tr.rvar(\"Survived\"), rf.predict(tr).firstClasses()).printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we have a good example of overfit. Why is that? Look at the confusion matrix on the training set. We fit too well the training data. This data set is well known for its high irreducible error. And there is an explanation for that. During the tragic event a lot of exceptional things happened. For example I read somewhere that an old lady which had a dog was not allowed to embark with her pet due to regulations. As a consequence she decided to not leave it and she chose to die with him. It's close to impossible to learn those kind of things, even if the information would be available. \n",
    "\n",
    "We should reduce the error somehow. We can try to decrease the overfit by adding more learners. Let's see if that would be enough for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.822222, mean=0.822222, se=NaN\n",
      "CV  2:  acc=0.831461, mean=0.826841, se=0.006533\n",
      "CV  3:  acc=0.876404, mean=0.843362, se=0.028986\n",
      "CV  4:  acc=0.820225, mean=0.837578, se=0.026343\n",
      "CV  5:  acc=0.786517, mean=0.827366, se=0.032279\n",
      "CV  6:  acc=0.831461, mean=0.828048, se=0.028919\n",
      "CV  7:  acc=0.752809, mean=0.817300, se=0.038803\n",
      "CV  8:  acc=0.831461, mean=0.819070, se=0.036271\n",
      "CV  9:  acc=0.842697, mean=0.821695, se=0.034831\n",
      "CV 10:  acc=0.719101, mean=0.811436, se=0.046162\n",
      "==============\n",
      "Mean accuracy:0.811436\n",
      "SE: 0.046162     (Standard error)\n",
      "> Confusion\n",
      "\n",
      " Ac\\Pr |    0    1 | total\n",
      " ----- |    -    - | -----\n",
      "     0 | >526   23 |   549\n",
      "     1 |   44 >298 |   342\n",
      " ----- |    -    - | -----\n",
      " total |  570  321 |   891\n",
      "\n",
      "\n",
      "Complete cases 891 from 891\n",
      "Acc: 0.9248036         (Accuracy )\n",
      "F1:  0.9401251         (F1 score / F-measure)\n",
      "MCC: 0.8402332         (Matthew correlation coefficient)\n",
      "Pre: 0.922807         (Precision)\n",
      "Rec: 0.9581056         (Recall)\n",
      "G:   0.9402907         (G-measure)\n"
     ]
    }
   ],
   "source": [
    "RandomSource.setSeed(123);\n",
    "Frame tr = train.mapVars(\"Survived,Sex,Pclass,Embarked,Age,Fare,SibSp,Parch\");\n",
    "CForest rf = CForest.newRF().withRuns(500);\n",
    "CEvaluation.cv(tr, \"Survived\", rf, 10);\n",
    "\n",
    "rf.fit(tr, \"Survived\");\n",
    "CPrediction fit = rf.predict(test);\n",
    "new Confusion(tr.rvar(\"Survived\"), rf.predict(tr).firstClasses()).printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly better than before. But the difference does not look significantly better than previous. We will use a simple pre-pruning strategy is to limit the number instances in leaf nodes. We set the minimum count to $3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossValidation with 10 folds\n",
      "CV  1:  acc=0.800000, mean=0.800000, se=NaN\n",
      "CV  2:  acc=0.820225, mean=0.810112, se=0.014301\n",
      "CV  3:  acc=0.887640, mean=0.835955, se=0.045889\n",
      "CV  4:  acc=0.820225, mean=0.832022, se=0.038285\n",
      "CV  5:  acc=0.775281, mean=0.820674, se=0.041752\n",
      "CV  6:  acc=0.853933, mean=0.826217, se=0.039736\n",
      "CV  7:  acc=0.775281, mean=0.818941, se=0.041066\n",
      "CV  8:  acc=0.808989, mean=0.817697, se=0.038182\n",
      "CV  9:  acc=0.853933, mean=0.821723, se=0.037703\n",
      "CV 10:  acc=0.719101, mean=0.811461, se=0.048132\n",
      "==============\n",
      "Mean accuracy:0.811461\n",
      "SE: 0.048132     (Standard error)\n",
      "> Confusion\n",
      "\n",
      " Ac\\Pr |    0    1 | total\n",
      " ----- |    -    - | -----\n",
      "     0 | >520   29 |   549\n",
      "     1 |   67 >275 |   342\n",
      " ----- |    -    - | -----\n",
      " total |  587  304 |   891\n",
      "\n",
      "\n",
      "Complete cases 891 from 891\n",
      "Acc: 0.8922559         (Accuracy )\n",
      "F1:  0.915493         (F1 score / F-measure)\n",
      "MCC: 0.7706188         (Matthew correlation coefficient)\n",
      "Pre: 0.8858603         (Precision)\n",
      "Rec: 0.9471767         (Recall)\n",
      "G:   0.9160056         (G-measure)\n"
     ]
    }
   ],
   "source": [
    "RandomSource.setSeed(123);\n",
    "Frame tr = train.mapVars(\"Survived,Sex,Pclass,Embarked,Age,Fare,SibSp,Parch\");\n",
    "CForest rf = CForest.newRF()\n",
    ".withClassifier(CTree.newCART().withMinCount(3))\n",
    ".withRuns(100);\n",
    "CEvaluation.cv(tr, \"Survived\", rf, 10);\n",
    "\n",
    "rf.fit(tr, \"Survived\");\n",
    "CPrediction fit = rf.predict(test);\n",
    "new Confusion(tr.rvar(\"Survived\"), rf.predict(tr).firstClasses()).printSummary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we changed the classifier used by `CForest`. This is the same classifier used by default by random forest. We do this because we customized the classifier by changing the min count parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That had indeed some effect. However after submitting to competition we did not saw any improvement. We should look forward to engineer a little bit our features for further improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".java",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "10.0.2+13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
